<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>High-Performance Load Balancing with NGINX - anhduc720</title><meta name="gridsome:hash" content="bec6d12cb0812647832cd849fe018f0c4d8e006b"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.23"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><meta data-vue-tag="ssr" name="theme-color" content="#10c186"><meta data-vue-tag="ssr" name="google-site-verification" content="undefined"><meta data-vue-tag="ssr" name="apple-mobile-web-app-status-bar-style" content="default"><meta data-vue-tag="ssr" data-key="description" name="description" content="undefined"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.559c27a1344774b013969e7a1468d85b.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.559c27a1344774b013969e7a1468d85b.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/assets/static/favicon.b9532cc.559c27a1344774b013969e7a1468d85b.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/assets/static/favicon.f22e9f3.559c27a1344774b013969e7a1468d85b.png"><link data-vue-tag="ssr" rel="manifest" href="/manifest.json"><link rel="preload" href="/assets/css/0.styles.d7dd3f34.css" as="style"><link rel="preload" href="/assets/js/app.027d8017.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--doc-vue.d7c88996.js" as="script"><link rel="prefetch" href="/assets/js/page--node-modules--gridsome--app--pages--404-vue.6b6c43ea.js"><link rel="prefetch" href="/assets/js/page--src--pages--about-me-vue.fc7e614c.js"><link rel="prefetch" href="/assets/js/page--src--pages--index-vue.5cfae88c.js"><link rel="prefetch" href="/assets/js/page--src--templates--tag-vue.fca05169.js"><link rel="stylesheet" href="/assets/css/0.styles.d7dd3f34.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
  </head>
  <body >
    <div data-server-rendered="true" id="app" class="site" data-v-3b13e215><header class="header" data-v-57449993><a href="/" title="Back to home" class="logo active" data-v-595f1fa8 data-v-57449993><!----><div data-v-595f1fa8 data-v-595f1fa8><img alt="logo" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 2560 669' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-7036710eef043836d76d365abfd7f136'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-7036710eef043836d76d365abfd7f136)' width='2560' height='669' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAARCAYAAABtu6qMAAAACXBIWXMAAAsTAAALEwEAmpwYAAAE3UlEQVRYw92XW4iVVRTHz3du3z4KznHEZrTQTDg5MeSghUKJpjZNPmSQPfQo6MsEIvg0CkKFoiCUGhTeEA26waihXQgvo3lBnZBJSQ1xfFAqQSe0HKwc/2uf/zqzzvabGR98qQ9%2b7LUv37f3WnuttfeXSuGJD9WktATpSr3D1yP2vQDWgpj1tHkn9aifbDbry1wulyjbR9qtbMcP%2bdjFu45iOmyPO4oZ1reAXlAwYypGcI/QCKqAVXYoZULDPJTy9lHlocx0MJJyhHZV9mfQTnkqGEs5Yw0mC9HJRVaS%2bnS3wjEgovw42AtWUqlIx%2bq7LNMcvxAcQVsj6%2blwHeF8ZeUPFbNUosWdGdmHcjnrOZZPumNFaV/I%2bjXQZfornmAUiVRZlOlwV7kIaU/LOFXOGCfiu1%2bhfpxyxhjHfivD8hmM6QPNQbtfg84h36l4CBatyk9zR72Sl8ATQd9b7oTva2B9kfvJG%2bqbMBxUeSPH6pJRFCW6a%2bjKdlchfwz524HcPZhrBMb3oJwTGj7psUYoMb5vGOXTrj/%2bPwWXGSr6zlJ33hthh9QLP9T6kMmmMrpDE8EnYD9YYlxY%2byejvgvlCnAUtNlFS8n6JtRPg8/ANmsE861x4ADYAXrwzstsz7IcC3ahvVWMA74Dk1SRMeA3cA80Mvtnzckgp0I32Kkxb/LFqsLFWjHC%2b2qcXFOscdcCFoAG8C8YH8RljAVdRXkGrAK3ZQdN%2bKgBPkT9d7BM3Btlk35HXJnydnABtDIEZmkImJxzCvL3sg4bJqLEOcb3TFU%2biOsGd9L3v1nOF94gNjludue8J7TRCFHuuVgnrQWvgjtAdyVj3PsE5NUoZYf%2bAROMcjpmK%2boH2X4TzLfxTfkiWEPPEeVmG29SI%2b1kPpHnFmQfJqnChdpKckMyzOtOmuze6g57A4zXk8GWlI%2b5s94IzWZRjaAbtIO7anEmIE1wP6LvPZQN4G/ITyUYYBtdNg/5VmgAKvQrvWgY6MW4ucYD9DtfADlRhnNM2QDuiFeuE4ywO2/if58cgcYw4cnxBhPkQfkGNFMXXw26KN/GhC3GA9QAnTRACdxVAzBjWw8QA0DM/YHytcAAkleucL4sjT0nNADkLyHv4Zg7FQNg0Qtcl9%2b9w2Z3VfkCuA42WqO4/tNhljvllZc7wnC/4NkuzwnXgvNgeng0GQ/oYgiUGN%2bVEDBhsp0JTt7rtR5glJP%2b3eDZhByghtrKZPsix8y0t8HFjOP24JY4xXV6BeeZhKjGaYJBpO8qqGP%2byOAU0EXNEFcTy4PLYIPurjkFJAl%2bDt6ley8JsncdkDxxEryNMTdQbjRXXlWuWeIafM2wW29OHZ3vJa5HTp5L4IPwBtjGfPCRMcByHo91gWdMAD3gTzDR3hka%2b7bY214JFEm9PXtRDmPyGy2KQq4Ho4LLUh6MoSFkXD14LLgi61H4NG%2bOVXMFt88SE3ONjinf45G5Ka8rdHsjLGNdwuJ0YKgM%2bMUd97s/xYaEPwbzuaqFDXoBGaRvsAtMwn9CNNQcSXPGcVzZaZvR14HnZUfBX%2bAddW8kPusZr5eV7lc%2buAprLEdKqKBejHjuRwNcl3VMlTzAtfqBuYYaU/UrrGc766/wv2CGif/EHyh7Ovwnnyoj8C4g93/%2b8NQE579XHOP%2bF8rfB8rMg9zyj6XAAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" width="2560" data-src="/assets/static/logo-dark.42db587.08b82fc9486f721bb5058dbc06db0c39.svg" data-srcset="/assets/static/logo-dark.82a2fbd.08b82fc9486f721bb5058dbc06db0c39.svg 480w, /assets/static/logo-dark.cbab2cf.08b82fc9486f721bb5058dbc06db0c39.svg 1024w, /assets/static/logo-dark.2665e34.08b82fc9486f721bb5058dbc06db0c39.svg 1920w, /assets/static/logo-dark.42db587.08b82fc9486f721bb5058dbc06db0c39.svg 2560w" data-sizes="(max-width: 2560px) 100vw, 2560px" class="g-image g-image--lazy g-image--loading" data-v-595f1fa8><noscript data-v-595f1fa8><img src="/assets/static/logo-dark.42db587.08b82fc9486f721bb5058dbc06db0c39.svg" class="g-image g-image--loaded" width="2560" alt="logo"></noscript></div></a><nav class="nav" data-v-57449993><button id="themeSwitch" aria-label="Switch theme between light and dark" data-v-1097eb34 data-v-57449993><!----><!----></button><button aria-label="Toggle the sidebar" class="toggle" data-v-def1a688 data-v-57449993><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="open feather feather-menu" data-v-def1a688 data-v-def1a688><line x1="3" y1="12" x2="21" y2="12" data-v-def1a688></line><line x1="3" y1="6" x2="21" y2="6" data-v-def1a688></line><line x1="3" y1="18" x2="21" y2="18" data-v-def1a688></line></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="close feather feather-x" style="display:none;" data-v-def1a688 data-v-def1a688><line x1="18" y1="6" x2="6" y2="18" data-v-def1a688></line><line x1="6" y1="6" x2="18" y2="18" data-v-def1a688></line></svg></button></nav></header><aside class="sidebar" data-v-fabd13e2><nav data-v-fabd13e2><ul data-v-fabd13e2><li class="section" data-v-fabd13e2><h3 class="section-title" data-v-fabd13e2>Introduction</h3><ul data-v-fabd13e2><li data-v-fabd13e2><a href="/about-me" class="topic" data-v-fabd13e2>About me</a></li></ul></li><li class="section" data-v-fabd13e2><h3 class="section-title" data-v-fabd13e2>Content</h3><ul data-v-fabd13e2><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#how-distribute-load-between-two-or-more-http-servers" class="sub-topic" data-v-fabd13e2>How distribute load between two or more HTTP servers?</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#how-distribute-load-between-two-or-more-tcp-servers" class="sub-topic" data-v-fabd13e2>How distribute load between two or more TCP servers?</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#how-distribute-load-between-two-or-more-udp-servers" class="sub-topic" data-v-fabd13e2>How distribute load between two or more UDP servers?</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#what-load-balancing-method-should-i-use" class="sub-topic" data-v-fabd13e2>What load-balancing method should I use?</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#round-robin" class="sub-topic" data-v-fabd13e2>Round robin</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#least-connections" class="sub-topic" data-v-fabd13e2>Least connections</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#least-time" class="sub-topic" data-v-fabd13e2>Least time</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#generic-hash" class="sub-topic" data-v-fabd13e2>Generic hash</a></li><li data-v-fabd13e2><a href="/blogs/high-performance-load-balancing-with-nginx/#random" class="sub-topic" data-v-fabd13e2>Random</a></li></ul></li></ul><a href="https://github.com/anhduc720" title="Git-repository" aria-label="anhduc720 on Github" class="git small" data-v-4b3d94ee data-v-fabd13e2><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-github" data-v-4b3d94ee data-v-4b3d94ee><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" data-v-4b3d94ee data-v-4b3d94ee></path></svg>
  Fork me on Github
</a></nav></aside><main class="main"><h1 data-v-3b13e215>
    High-Performance Load Balancing with NGINX
  </h1><div class="markdown" data-v-3b13e215><p>Hiện nay, trải nghiệm người dùng internet yêu cầu hiệu năng và thời gian hoạt động. Để đáp ứng những điều này, nhiều instance của cùng một hệ thống được chạy, và tải được phân phối tới chúng. Khi lượng tải tăng lên. Thêm một instance khác được khởi động và đưa vào hệ thống để chia một phần tải, kỹ thuật của kiến trúc này được gọi là mở rộng theo chiều ngang (horizontal scaling). Cơ sở hạ tầng dựa trên phần mềm đang ngày càng phổ biến vì tính linh hoạt của nó, mở ra một thế giới rộng lớn về khả năng. Cho dù trường hợp sử dụng nhỏ như chỉ cần 2 instance hoặc lớn như hàng ngàn instance trên toàn cầu, thì cũng cần một giải pháp cân bằng tải năng động như cơ sở hạ tầng. NGINX đáp ứng nhu cầu này theo một số cách, chẳng hạn như cân bằng tải HTTP, TCP và UDP, mà tôi đề cập trong bài viết này.</p>
<p>Khi cân bằng tải, điều quan trọng là chỉ một instance tương tác đến một khách hàng. Nhiều kiến trúc web hiện đại sử dụng các tầng ứng dụng phi trạng thái, lưu trữ trạng thái trong bộ nhớ hoặc cơ sở dữ liệu dùng chung. Tuy nhiên, không thể áp dụng điều này cho tất cả các ứng dụng. Trạng thái session là vô cùng có giá trị trong các ứng dụng tương tác. Trạng thái này có thể được lưu trữ cục bộ đến máy chủ ứng dụng vì một số lý do; ví dụ, trong các ứng dụng mà dữ liệu đang hoạt động quá lớn đến mức chi phí mạng quá đắt. Khi trạng thái được lưu trữ cục bộ đến một máy chủ ứng dụng, điều cực kỳ quan trọng đối với trải nghiệm người dùng là các yêu cầu tiếp theo được tiếp tục được gửi đến cùng một máy chủ. Một khía cạnh khác của tình huống là các máy chủ không nên được thoát ra cho đến khi session kết thúc. Làm việc với các ứng dụng trạng thái ở quy mô đòi hỏi một bộ cân bằng tải thông minh. NGINX Plus cung cấp nhiều cách để giải quyết vấn đề này bằng cách theo dõi cookie hoặc định tuyến.</p>
<p>Bài viết này cũng đề cập tới session persistence và sự liên quan của nó trong viêch cân bằng tải với NGINX và NGINX Plus</p>
<h3 id="how-distribute-load-between-two-or-more-http-servers"><a href="#how-distribute-load-between-two-or-more-http-servers" aria-hidden="true"><span class="icon icon-link"></span></a>How distribute load between two or more HTTP servers?</h3>
<p>Config upstream block để cân bằng tải giữa 2 HTTP servers bằng NGINX’s HTTP module :</p>
<pre class="language-text">upstream backend {
    server 10.10.12.45:80      weight=1;
    server app.example.com:80  weight=2;
}
server {
    location / {
        proxy_pass http://backend;
    }
}</pre>
<p>cấu hình này sẽ cân bằng tải giữa 2 HTTP server ở cổng 80. Nginx sẽ dựa vào weight parameter để điều phối lượng kết nối giữa 2 server. Giá trị mặc định này là 1.</p>
<p>HTTP upstream module điều khiển cân bằng tải cho HTTP. Module này định nghĩa một set các điểm đích bao gồm Unix socket, địa chỉ IP, và DNS records. Upstream module còn định nghĩa bao nhiêu request đơn được assigned tới từng upstream servers</p>
<h3 id="how-distribute-load-between-two-or-more-tcp-servers"><a href="#how-distribute-load-between-two-or-more-tcp-servers" aria-hidden="true"><span class="icon icon-link"></span></a>How distribute load between two or more TCP servers?</h3>
<p>Config upstream block để cân bằng tải giữa 2 TCP servers bằng NGINX’s stream module :</p>
<pre class="language-text">stream {
    upstream mysql_read {
        server read1.example.com:3306  weight=5;
        server read2.example.com:3306;
        server 10.10.12.34:3306        backup;
    }

    server {
        listen 3306;
        proxy_pass mysql_read;
    }
}</pre>
<p>block server ở ví dụ này chỉ định NGINX nghe ở cổng TCP 3306 và cân bằng tải giữa 2 instance MySQL chỉ đọc và liệt kê một instance dự phòng khác. Traffic sẽ được điều hướng tới instance này nếu như 2 instance chính failed.</p>
<h3 id="how-distribute-load-between-two-or-more-udp-servers"><a href="#how-distribute-load-between-two-or-more-udp-servers" aria-hidden="true"><span class="icon icon-link"></span></a>How distribute load between two or more UDP servers?</h3>
<p>Config upstream block định nghĩa udp để cân bằng tải giữa 2 UDP servers bằng NGINX’s stream module :</p>
<pre class="language-text">stream {
    upstream ntp {
        server ntp1.example.com:123  weight=2;
        server ntp2.example.com:123;
    }

    server {
        listen 123 udp;
        proxy_pass ntp;
    }
}</pre>
<p>Phần cấu hình này cân bằng tải giữa hai máy chủ Giao thức thời gian mạng (NTP) sử dụng giao thức UDP. Chỉ định cân bằng tải UDP đơn giản như sử dụng tham số udp trên listen directive.</p>
<p>Nếu dịch vụ bạn cân bằng tải yêu cầu nhiều gói được gửi qua lại giữa máy khách và máy chủ, bạn có thể chỉ định tham số reuseport. Ví dụ về các loại dịch vụ này là OpenVPN, Giao thức thoại qua Internet (VoIP), giải pháp máy tính để bàn ảo và Bảo mật lớp truyền tải dữ liệu (DTLS). Sau đây là một ví dụ về việc sử dụng NGINX để xử lý các kết nối OpenVPN và ủy quyền chúng cho dịch vụ OpenVPN chạy cục bộ:</p>
<pre class="language-text">stream {
    server {
        listen 1195 udp reuseport;
        proxy_pass 127.0.0.1:1194;
    }
}</pre>
<p>Bạn có thể thắc mắc, "Tại sao tôi cần một bộ cân bằng tải khi tôi có thể có nhiều máy chủ trong DNS A record hoặc SRV record?" Câu trả lời là: chúng ta không những có các thuật toán cân bằng thay thế mà chúng ta còn có thể tải cân bằng chính các máy chủ DNS. Các dịch vụ UDP tạo nên rất nhiều dịch vụ mà ta phụ thuộc vào trong các hệ thống mạng, chẳng hạn như DNS, NTP và VoIP. Cân bằng tải UDP có thể ít phổ biến hơn đối với một số người nhưng cũng hữu ích.</p>
<p>Bạn có thể tìm thấy cân bằng tải UDP trong strem module, giống như TCP và cấu hình nó tương tự. Sự khác biệt chính là chỉ thị lắng nghe xác định rằng open socket để làm việc với datagram. Khi làm việc với datagram, có một số chỉ thị khác có thể áp dụng khi chúng không có trong TCP, chẳng hạn như chỉ thị proxy_response, chỉ định NGINX có thể gửi bao nhiêu phản hồi dự kiến từ upstream server. Theo mặc định, cái này là không giới hạn cho đến khi đạt đến giới hạn proxy_timeout.</p>
<p>Tham số reuseport hướng dẫn NGINX tạo một socket nghe riêng cho mỗi worker process. Điều này cho phép kernel phân phối các kết nối đến giữa các worker process để xử lý nhiều gói được gửi giữa máy khách và máy chủ. Tính năng reuseport chỉ hoạt động trên Linux kernels 3.9 trở lên, DragonFly BSD và FreeBSD 12 trở lên.</p>
<h3 id="what-load-balancing-method-should-i-use"><a href="#what-load-balancing-method-should-i-use" aria-hidden="true"><span class="icon icon-link"></span></a>What load-balancing method should I use?</h3>
<p>Nếu Cân bằng tải kiểu round-robin không phù hợp với trường hợp của bạn vì bạn có khối lượng công việc hoặc các máy chủ không đồng nhất, hãy sử dụng một trong những phương thức cân bằng tải sau:
least connections, least time, generic hash, IP hash, or random</p>
<pre class="language-text">upstream backend {
    least_conn;
    server backend.example.com;
    server backend1.example.com;
}</pre>
<p>Ví dụ trên sử dụng cân bằng tải theo thuật toán ít kết nối nhất (least connections). Tất cả các thuật toán cân bằng tải, trừ generic hash, random, and least-time đều là chỉ thị độc lập. </p>
<p>Không phải tất cả yêu các yêu cầu hoặc gói tin đều mang trọng lượng như nhau.Với điều này, round-robin, hoặc thậm chí là round-robin có trọng số được sử dụng trong các ví dụ trước, sẽ không phù hợp với ứng dụng hoặc luồng lưu lượng. NGINX cung cấp một số thuật toán cân bằng tải mà bạn có thể sử dụng để phù hợp với các trường hợp sử dụng cụ thể. Ngoài việc có thể chọn các thuật toán hoặc phương pháp cân bằng tải này, bạn cũng có thể cấu hình chúng. Các phương pháp cân bằng tải sau đây có sẵn cho các nhóm HTTP, TCP và UDP upstream.</p>
<h3 id="round-robin"><a href="#round-robin" aria-hidden="true"><span class="icon icon-link"></span></a>Round robin</h3>
<p>Đây là thuật toán cân bằng tải mặc đinh. Nó phân phối lưu lượng theo thứ tự cho một danh sách các server trong pool. Bạn có thể thêm vào trọng số để trở thành weighted round-robin, nếu như khả năng phục vụ request của các server trong pool là khác nhau. giá trị trọng số của một server càng cao, càng nhiều request được chuyển tới server đó.</p>
<h3 id="least-connections"><a href="#least-connections" aria-hidden="true"><span class="icon icon-link"></span></a>Least connections</h3>
<p>Phương thức này cân bằng tải bằng cách chuyển request tới server có số lượng kết nối đang mở thấp nhất. Cũng giống như round-robin, bạn có thể thêm trọng số vào server để điều chỉnh server đích sẽ nhận request.
Tên chỉ thị là <code class="language-text">least_conn</code>.</p>
<h3 id="least-time"><a href="#least-time" aria-hidden="true"><span class="icon icon-link"></span></a>Least time</h3>
<p>Chỉ có trên NGINX Plus.Nó gần giống với leat connection trong đó nó Chuyển kết nối cho server với số lượng kết nối hiện tại ít nhất nhưng ưu tiên các máy chủ có thời gian phản hồi trung bình thấp nhất. Phương pháp này là một trong những thuật toán cân bằng tải tinh vi nhất và phù hợp với nhu cầu của các ứng dụng web có hiệu suất cao. Thuật toán này tốt hơn <code class="language-text">Least connections</code> vì số lượng kết nối nhỏ nhất không nhất thiết có nghĩa là phản ứng nhanh nhất. Một tham số của <code class="language-text">header</code> hoặc <code class="language-text">last_byte</code> phải được chỉ định cho lệnh này. Khi <code class="language-text">header</code> được chỉ định, thời gian để nhận tiêu đề phản hồi được sử dụng. Khi <code class="language-text">last_byte</code> được chỉ định, thời gian nhận phản hồi đầy đủ được sử dụng.
Tên chỉ thị là <code class="language-text">less_time</code>.</p>
<h3 id="generic-hash"><a href="#generic-hash" aria-hidden="true"><span class="icon icon-link"></span></a>Generic hash</h3>
<p>NGINX lựa chọn server dựa trên một key được user định nghĩa trước. vi dụ IP nguồn của request($remote_addr)</p>
<pre class="language-text">upstream stream_backend {
    hash $remote_addr;
    server backend1.example.com:12345;
    server backend2.example.com:12345;
    server backend3.example.com:12346;
}</pre>
<p>Phương thức cân bằng tải kiểu băm cũng được sử dụng để lưu trữ session. Vì hash function dựa trên IP của máy khách, tất cả các kết nối đến từ một client sẽ luôn luôn được chuyển tới cùng một server trừ khi server đó bị tắt hoặc không khả dụng.
Tên chỉ thị là <code class="language-text">hash</code>.</p>
<h3 id="random"><a href="#random" aria-hidden="true"><span class="icon icon-link"></span></a>Random</h3>
<p>Mỗi kết nối được chuyển một cách ngẫu nhiên tới server đích. nếu chỉ thị có param <code class="language-text">two</code>. Đầu tiên, NGINX sẽ chọn ngẫu nhiên ra 2 server. Sau đó, chọn 1 trong 2 server dựa theo các phương thức sau:</p>
<ul>
<li>least_conn – Ít kết nối đang hoạt động nhất</li>
<li>least_time=connect (NGINX Plus) – thời gian kết nối tới server thấp nhất ($upstream_connect_time).</li>
<li>least_time=first_byte (NGINX Plus) – thời gian nhận byte data đầu tiên thấp nhất ($upstream_first_byte_time).</li>
<li>least_time=last_byte (NGINX Plus) – thời gian nhận byte data cuối cùng thấp nhất ($upstream_last_byte_time) </li>
</ul>
<pre class="language-text">upstream stream_backend {
  random two least_time=last_byte;
  server backend1.example.com:12345;
  server backend2.example.com:12345;
  server backend3.example.com:12346;
  server backend4.example.com:12346;
}</pre>
<p>Phương thức cân bằng tải ngẫu nhiên thường đượch sử dụng trong nhưng môi trường phân tán, nơi mà nhiều bộ cân bằng tải đồng thời chuyển request tới một số backend servers. Trong những môi trường mà bộ cân bằng tải có cái nhìn toàn cảnh về các request, Ta nên sử dụng các phương thức cân bằng tải khác như round-robin, least connection, hay lest time.</p>
</div></main></div>
    <script>window.__INITIAL_STATE__={"data":{"doc":{"title":"High-Performance Load Balancing with NGINX","path":"\u002Fblogs\u002Fhigh-performance-load-balancing-with-nginx\u002F","slug":"high-performance-load-balancing-with-nginx","date":"12. March 2019","timeToRead":8,"content":"\u003Cp\u003EHiện nay, trải nghiệm người dùng internet yêu cầu hiệu năng và thời gian hoạt động. Để đáp ứng những điều này, nhiều instance của cùng một hệ thống được chạy, và tải được phân phối tới chúng. Khi lượng tải tăng lên. Thêm một instance khác được khởi động và đưa vào hệ thống để chia một phần tải, kỹ thuật của kiến trúc này được gọi là mở rộng theo chiều ngang (horizontal scaling). Cơ sở hạ tầng dựa trên phần mềm đang ngày càng phổ biến vì tính linh hoạt của nó, mở ra một thế giới rộng lớn về khả năng. Cho dù trường hợp sử dụng nhỏ như chỉ cần 2 instance hoặc lớn như hàng ngàn instance trên toàn cầu, thì cũng cần một giải pháp cân bằng tải năng động như cơ sở hạ tầng. NGINX đáp ứng nhu cầu này theo một số cách, chẳng hạn như cân bằng tải HTTP, TCP và UDP, mà tôi đề cập trong bài viết này.\u003C\u002Fp\u003E\n\u003Cp\u003EKhi cân bằng tải, điều quan trọng là chỉ một instance tương tác đến một khách hàng. Nhiều kiến trúc web hiện đại sử dụng các tầng ứng dụng phi trạng thái, lưu trữ trạng thái trong bộ nhớ hoặc cơ sở dữ liệu dùng chung. Tuy nhiên, không thể áp dụng điều này cho tất cả các ứng dụng. Trạng thái session là vô cùng có giá trị trong các ứng dụng tương tác. Trạng thái này có thể được lưu trữ cục bộ đến máy chủ ứng dụng vì một số lý do; ví dụ, trong các ứng dụng mà dữ liệu đang hoạt động quá lớn đến mức chi phí mạng quá đắt. Khi trạng thái được lưu trữ cục bộ đến một máy chủ ứng dụng, điều cực kỳ quan trọng đối với trải nghiệm người dùng là các yêu cầu tiếp theo được tiếp tục được gửi đến cùng một máy chủ. Một khía cạnh khác của tình huống là các máy chủ không nên được thoát ra cho đến khi session kết thúc. Làm việc với các ứng dụng trạng thái ở quy mô đòi hỏi một bộ cân bằng tải thông minh. NGINX Plus cung cấp nhiều cách để giải quyết vấn đề này bằng cách theo dõi cookie hoặc định tuyến.\u003C\u002Fp\u003E\n\u003Cp\u003EBài viết này cũng đề cập tới session persistence và sự liên quan của nó trong viêch cân bằng tải với NGINX và NGINX Plus\u003C\u002Fp\u003E\n\u003Ch3 id=\"how-distribute-load-between-two-or-more-http-servers\"\u003E\u003Ca href=\"#how-distribute-load-between-two-or-more-http-servers\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EHow distribute load between two or more HTTP servers?\u003C\u002Fh3\u003E\n\u003Cp\u003EConfig upstream block để cân bằng tải giữa 2 HTTP servers bằng NGINX’s HTTP module :\u003C\u002Fp\u003E\n\u003Cpre class=\"language-text\"\u003Eupstream backend {\n    server 10.10.12.45:80      weight=1;\n    server app.example.com:80  weight=2;\n}\nserver {\n    location \u002F {\n        proxy_pass http:\u002F\u002Fbackend;\n    }\n}\u003C\u002Fpre\u003E\n\u003Cp\u003Ecấu hình này sẽ cân bằng tải giữa 2 HTTP server ở cổng 80. Nginx sẽ dựa vào weight parameter để điều phối lượng kết nối giữa 2 server. Giá trị mặc định này là 1.\u003C\u002Fp\u003E\n\u003Cp\u003EHTTP upstream module điều khiển cân bằng tải cho HTTP. Module này định nghĩa một set các điểm đích bao gồm Unix socket, địa chỉ IP, và DNS records. Upstream module còn định nghĩa bao nhiêu request đơn được assigned tới từng upstream servers\u003C\u002Fp\u003E\n\u003Ch3 id=\"how-distribute-load-between-two-or-more-tcp-servers\"\u003E\u003Ca href=\"#how-distribute-load-between-two-or-more-tcp-servers\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EHow distribute load between two or more TCP servers?\u003C\u002Fh3\u003E\n\u003Cp\u003EConfig upstream block để cân bằng tải giữa 2 TCP servers bằng NGINX’s stream module :\u003C\u002Fp\u003E\n\u003Cpre class=\"language-text\"\u003Estream {\n    upstream mysql_read {\n        server read1.example.com:3306  weight=5;\n        server read2.example.com:3306;\n        server 10.10.12.34:3306        backup;\n    }\n\n    server {\n        listen 3306;\n        proxy_pass mysql_read;\n    }\n}\u003C\u002Fpre\u003E\n\u003Cp\u003Eblock server ở ví dụ này chỉ định NGINX nghe ở cổng TCP 3306 và cân bằng tải giữa 2 instance MySQL chỉ đọc và liệt kê một instance dự phòng khác. Traffic sẽ được điều hướng tới instance này nếu như 2 instance chính failed.\u003C\u002Fp\u003E\n\u003Ch3 id=\"how-distribute-load-between-two-or-more-udp-servers\"\u003E\u003Ca href=\"#how-distribute-load-between-two-or-more-udp-servers\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EHow distribute load between two or more UDP servers?\u003C\u002Fh3\u003E\n\u003Cp\u003EConfig upstream block định nghĩa udp để cân bằng tải giữa 2 UDP servers bằng NGINX’s stream module :\u003C\u002Fp\u003E\n\u003Cpre class=\"language-text\"\u003Estream {\n    upstream ntp {\n        server ntp1.example.com:123  weight=2;\n        server ntp2.example.com:123;\n    }\n\n    server {\n        listen 123 udp;\n        proxy_pass ntp;\n    }\n}\u003C\u002Fpre\u003E\n\u003Cp\u003EPhần cấu hình này cân bằng tải giữa hai máy chủ Giao thức thời gian mạng (NTP) sử dụng giao thức UDP. Chỉ định cân bằng tải UDP đơn giản như sử dụng tham số udp trên listen directive.\u003C\u002Fp\u003E\n\u003Cp\u003ENếu dịch vụ bạn cân bằng tải yêu cầu nhiều gói được gửi qua lại giữa máy khách và máy chủ, bạn có thể chỉ định tham số reuseport. Ví dụ về các loại dịch vụ này là OpenVPN, Giao thức thoại qua Internet (VoIP), giải pháp máy tính để bàn ảo và Bảo mật lớp truyền tải dữ liệu (DTLS). Sau đây là một ví dụ về việc sử dụng NGINX để xử lý các kết nối OpenVPN và ủy quyền chúng cho dịch vụ OpenVPN chạy cục bộ:\u003C\u002Fp\u003E\n\u003Cpre class=\"language-text\"\u003Estream {\n    server {\n        listen 1195 udp reuseport;\n        proxy_pass 127.0.0.1:1194;\n    }\n}\u003C\u002Fpre\u003E\n\u003Cp\u003EBạn có thể thắc mắc, \"Tại sao tôi cần một bộ cân bằng tải khi tôi có thể có nhiều máy chủ trong DNS A record hoặc SRV record?\" Câu trả lời là: chúng ta không những có các thuật toán cân bằng thay thế mà chúng ta còn có thể tải cân bằng chính các máy chủ DNS. Các dịch vụ UDP tạo nên rất nhiều dịch vụ mà ta phụ thuộc vào trong các hệ thống mạng, chẳng hạn như DNS, NTP và VoIP. Cân bằng tải UDP có thể ít phổ biến hơn đối với một số người nhưng cũng hữu ích.\u003C\u002Fp\u003E\n\u003Cp\u003EBạn có thể tìm thấy cân bằng tải UDP trong strem module, giống như TCP và cấu hình nó tương tự. Sự khác biệt chính là chỉ thị lắng nghe xác định rằng open socket để làm việc với datagram. Khi làm việc với datagram, có một số chỉ thị khác có thể áp dụng khi chúng không có trong TCP, chẳng hạn như chỉ thị proxy_response, chỉ định NGINX có thể gửi bao nhiêu phản hồi dự kiến từ upstream server. Theo mặc định, cái này là không giới hạn cho đến khi đạt đến giới hạn proxy_timeout.\u003C\u002Fp\u003E\n\u003Cp\u003ETham số reuseport hướng dẫn NGINX tạo một socket nghe riêng cho mỗi worker process. Điều này cho phép kernel phân phối các kết nối đến giữa các worker process để xử lý nhiều gói được gửi giữa máy khách và máy chủ. Tính năng reuseport chỉ hoạt động trên Linux kernels 3.9 trở lên, DragonFly BSD và FreeBSD 12 trở lên.\u003C\u002Fp\u003E\n\u003Ch3 id=\"what-load-balancing-method-should-i-use\"\u003E\u003Ca href=\"#what-load-balancing-method-should-i-use\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EWhat load-balancing method should I use?\u003C\u002Fh3\u003E\n\u003Cp\u003ENếu Cân bằng tải kiểu round-robin không phù hợp với trường hợp của bạn vì bạn có khối lượng công việc hoặc các máy chủ không đồng nhất, hãy sử dụng một trong những phương thức cân bằng tải sau:\nleast connections, least time, generic hash, IP hash, or random\u003C\u002Fp\u003E\n\u003Cpre class=\"language-text\"\u003Eupstream backend {\n    least_conn;\n    server backend.example.com;\n    server backend1.example.com;\n}\u003C\u002Fpre\u003E\n\u003Cp\u003EVí dụ trên sử dụng cân bằng tải theo thuật toán ít kết nối nhất (least connections). Tất cả các thuật toán cân bằng tải, trừ generic hash, random, and least-time đều là chỉ thị độc lập. \u003C\u002Fp\u003E\n\u003Cp\u003EKhông phải tất cả yêu các yêu cầu hoặc gói tin đều mang trọng lượng như nhau.Với điều này, round-robin, hoặc thậm chí là round-robin có trọng số được sử dụng trong các ví dụ trước, sẽ không phù hợp với ứng dụng hoặc luồng lưu lượng. NGINX cung cấp một số thuật toán cân bằng tải mà bạn có thể sử dụng để phù hợp với các trường hợp sử dụng cụ thể. Ngoài việc có thể chọn các thuật toán hoặc phương pháp cân bằng tải này, bạn cũng có thể cấu hình chúng. Các phương pháp cân bằng tải sau đây có sẵn cho các nhóm HTTP, TCP và UDP upstream.\u003C\u002Fp\u003E\n\u003Ch3 id=\"round-robin\"\u003E\u003Ca href=\"#round-robin\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003ERound robin\u003C\u002Fh3\u003E\n\u003Cp\u003EĐây là thuật toán cân bằng tải mặc đinh. Nó phân phối lưu lượng theo thứ tự cho một danh sách các server trong pool. Bạn có thể thêm vào trọng số để trở thành weighted round-robin, nếu như khả năng phục vụ request của các server trong pool là khác nhau. giá trị trọng số của một server càng cao, càng nhiều request được chuyển tới server đó.\u003C\u002Fp\u003E\n\u003Ch3 id=\"least-connections\"\u003E\u003Ca href=\"#least-connections\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003ELeast connections\u003C\u002Fh3\u003E\n\u003Cp\u003EPhương thức này cân bằng tải bằng cách chuyển request tới server có số lượng kết nối đang mở thấp nhất. Cũng giống như round-robin, bạn có thể thêm trọng số vào server để điều chỉnh server đích sẽ nhận request.\nTên chỉ thị là \u003Ccode class=\"language-text\"\u003Eleast_conn\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\u003Ch3 id=\"least-time\"\u003E\u003Ca href=\"#least-time\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003ELeast time\u003C\u002Fh3\u003E\n\u003Cp\u003EChỉ có trên NGINX Plus.Nó gần giống với leat connection trong đó nó Chuyển kết nối cho server với số lượng kết nối hiện tại ít nhất nhưng ưu tiên các máy chủ có thời gian phản hồi trung bình thấp nhất. Phương pháp này là một trong những thuật toán cân bằng tải tinh vi nhất và phù hợp với nhu cầu của các ứng dụng web có hiệu suất cao. Thuật toán này tốt hơn \u003Ccode class=\"language-text\"\u003ELeast connections\u003C\u002Fcode\u003E vì số lượng kết nối nhỏ nhất không nhất thiết có nghĩa là phản ứng nhanh nhất. Một tham số của \u003Ccode class=\"language-text\"\u003Eheader\u003C\u002Fcode\u003E hoặc \u003Ccode class=\"language-text\"\u003Elast_byte\u003C\u002Fcode\u003E phải được chỉ định cho lệnh này. Khi \u003Ccode class=\"language-text\"\u003Eheader\u003C\u002Fcode\u003E được chỉ định, thời gian để nhận tiêu đề phản hồi được sử dụng. Khi \u003Ccode class=\"language-text\"\u003Elast_byte\u003C\u002Fcode\u003E được chỉ định, thời gian nhận phản hồi đầy đủ được sử dụng.\nTên chỉ thị là \u003Ccode class=\"language-text\"\u003Eless_time\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\u003Ch3 id=\"generic-hash\"\u003E\u003Ca href=\"#generic-hash\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EGeneric hash\u003C\u002Fh3\u003E\n\u003Cp\u003ENGINX lựa chọn server dựa trên một key được user định nghĩa trước. vi dụ IP nguồn của request($remote_addr)\u003C\u002Fp\u003E\n\u003Cpre class=\"language-text\"\u003Eupstream stream_backend {\n    hash $remote_addr;\n    server backend1.example.com:12345;\n    server backend2.example.com:12345;\n    server backend3.example.com:12346;\n}\u003C\u002Fpre\u003E\n\u003Cp\u003EPhương thức cân bằng tải kiểu băm cũng được sử dụng để lưu trữ session. Vì hash function dựa trên IP của máy khách, tất cả các kết nối đến từ một client sẽ luôn luôn được chuyển tới cùng một server trừ khi server đó bị tắt hoặc không khả dụng.\nTên chỉ thị là \u003Ccode class=\"language-text\"\u003Ehash\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\u003Ch3 id=\"random\"\u003E\u003Ca href=\"#random\" aria-hidden=\"true\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003ERandom\u003C\u002Fh3\u003E\n\u003Cp\u003EMỗi kết nối được chuyển một cách ngẫu nhiên tới server đích. nếu chỉ thị có param \u003Ccode class=\"language-text\"\u003Etwo\u003C\u002Fcode\u003E. Đầu tiên, NGINX sẽ chọn ngẫu nhiên ra 2 server. Sau đó, chọn 1 trong 2 server dựa theo các phương thức sau:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003Eleast_conn – Ít kết nối đang hoạt động nhất\u003C\u002Fli\u003E\n\u003Cli\u003Eleast_time=connect (NGINX Plus) – thời gian kết nối tới server thấp nhất ($upstream_connect_time).\u003C\u002Fli\u003E\n\u003Cli\u003Eleast_time=first_byte (NGINX Plus) – thời gian nhận byte data đầu tiên thấp nhất ($upstream_first_byte_time).\u003C\u002Fli\u003E\n\u003Cli\u003Eleast_time=last_byte (NGINX Plus) – thời gian nhận byte data cuối cùng thấp nhất ($upstream_last_byte_time) \u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cpre class=\"language-text\"\u003Eupstream stream_backend {\n  random two least_time=last_byte;\n  server backend1.example.com:12345;\n  server backend2.example.com:12345;\n  server backend3.example.com:12346;\n  server backend4.example.com:12346;\n}\u003C\u002Fpre\u003E\n\u003Cp\u003EPhương thức cân bằng tải ngẫu nhiên thường đượch sử dụng trong nhưng môi trường phân tán, nơi mà nhiều bộ cân bằng tải đồng thời chuyển request tới một số backend servers. Trong những môi trường mà bộ cân bằng tải có cái nhìn toàn cảnh về các request, Ta nên sử dụng các phương thức cân bằng tải khác như round-robin, least connection, hay lest time.\u003C\u002Fp\u003E\n","headings":[{"value":"How distribute load between two or more HTTP servers?","anchor":"#how-distribute-load-between-two-or-more-http-servers"},{"value":"How distribute load between two or more TCP servers?","anchor":"#how-distribute-load-between-two-or-more-tcp-servers"},{"value":"How distribute load between two or more UDP servers?","anchor":"#how-distribute-load-between-two-or-more-udp-servers"},{"value":"What load-balancing method should I use?","anchor":"#what-load-balancing-method-should-i-use"},{"value":"Round robin","anchor":"#round-robin"},{"value":"Least connections","anchor":"#least-connections"},{"value":"Least time","anchor":"#least-time"},{"value":"Generic hash","anchor":"#generic-hash"},{"value":"Random","anchor":"#random"}]}},"context":{}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script><script src="/assets/js/app.027d8017.js" defer></script><script src="/assets/js/page--src--templates--doc-vue.d7c88996.js" defer></script>
  </body>
</html>
